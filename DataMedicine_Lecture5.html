<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>회귀와 분류</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 64px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h2 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h3 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h4 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h5 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h6 {
  padding-top: 69px;
  margin-top: -69px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Tutorial</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="https://yoonhohong.github.io">by Yoon H. Hong</a>
</li>
<li>
  <a href="http://www.github.com/yoonhohong/tutorial">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">회귀와 분류</h1>

</div>


<div id="basic-concepts-of-statistics-statistical-modeling" class="section level1">
<h1>Basic concepts of statistics &amp; statistical modeling</h1>
<p>우리는 표본의 정보를 사용하여 모집단의 특징을 추정할 수 있습니다. 예를 들어, 어떤 변수 Y의 모평균 <span class="math inline">\(\mu\)</span>를 알고자 한다고 해봅시다. 유감스럽게도 <span class="math inline">\(\mu\)</span>는 알려져 있지 않습니다. 그러나, 우리는 Y의 n개 관측치, <span class="math inline">\(y_1\)</span>, <span class="math inline">\(y_2\)</span>, …, <span class="math inline">\(y_n\)</span>를 알수 있고, 이를 사용하여 <span class="math inline">\(\mu\)</span>를 추정할 수 있습니다. 즉, 아래와 갈이 표본평균을 모평균(정확히 말하면 모평균의 추정치)으로 합리적으로 추정할 수 있습니다.</p>
<p><span class="math display">\[\hat{\mu}=\overline{y}\]</span></p>
<p>그럼, 표본평균은 모평균의 추정값으로 얼마나 정확한가요?<br />
일반적으로 이 질문에 대한 답은 표준 오차(standard error)를 계산하는 것입니다. 표준 오차는 추정치(여기서는 모평균의 추정치가 되겠네요)의 표준 편차입니다. 즉, 표본 평균의 표준 편차, 이것이 표준 오차이며 잘 알려진 식은 아래와 같습니다.</p>
<p><span class="math display">\[SE = \frac{\sigma}{\sqrt{n}}\]</span> <span class="math inline">\(\sigma\)</span>: 표본 표준 편차 <span class="math inline">\(n\)</span>: 관측치의 개수</p>
<p>[Standard error &amp; bootstrapping] [standard error and bootstrapping](<a href="https://www.youtube.com/watch?v=XNgt7F6FqDU" class="uri">https://www.youtube.com/watch?v=XNgt7F6FqDU</a>)</p>
<p>표준 오차는 신뢰구간을 계산하는데 사용될 수 있습니다. [동영상] [confidence interval](<a href="https://www.youtube.com/watch?v=TqOeMYtOc1w" class="uri">https://www.youtube.com/watch?v=TqOeMYtOc1w</a>)</p>
</div>
<div id="-linear-regression" class="section level1">
<h1>선형 회귀(linear regression)</h1>
<p>기계학습의 가장 단순한 기법인 선형 회귀에 관한 것을 먼저 살펴보겠습니다.</p>
<p>선형 회귀는 나중에 소개할 최근의 기계학습 기법만큼 흥미롭지 않을 수도 있지만, 여전히 유용하고 자주 사용되는 방법입니다. 사실 많은 기계학습 기법이 선형회귀의 일반화 혹은 확장으로 볼 수 있습니다. 따라서, 더 복잡한 기계학습 기법에 대해 학습하기 전에 선형회귀에 대해 잘 이해하는 것이 매우 중요합니다.</p>
<p><a href="https://www.youtube.com/watch?v=nk2CQITm_eo">Linear model: least squares, residuals, R^2, F-statistic</a></p>
<p><a href="https://www.youtube.com/watch?v=NF5_btOaCig&amp;list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU&amp;index=6">t-test and ANOVA</a></p>
<p>자, 그럼 이론은 이해했으니, 다음으로 실제로 선형 회귀 모델을 이용해봅시다.</p>
<p>먼저 gapminder 자료를 기억해봅시다.</p>
<ol style="list-style-type: decimal">
<li><p>gapminder 데이터에서 기대수명은 일인당 국민소득과 연관이 있다고 말할 수 있을까요?</p></li>
<li><p>일인당 국민소득과 기대수명의 관계를 선형 모델로 설명할 때, 선형모델은 두 변수간의 관계를 얼마나 잘 설명할 수 있을까요?</p></li>
<li><p>우리는 선형모델을 이용해서 일인당 국민소득으로 기대 수명을 얼마나 정확하게 예측할 수 있을까요?</p></li>
</ol>
<pre class="r"><code>library(gapminder)
library(dplyr)
library(ggplot2)</code></pre>
<pre class="r"><code>gapminder_1952 = gapminder %&gt;%
  filter(year == 1952) %&gt;%
  mutate(gdpPercap_log = log10(gdpPercap))</code></pre>
<pre class="r"><code>ggplot(gapminder_1952, aes(gdpPercap_log, lifeExp)) + geom_point()</code></pre>
<p><img src="DataMedicine_Lecture5_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>attach(gapminder_1952)</code></pre>
<p>linear model을 적합시키는 함수로 lm()을 사용합니다.</p>
<pre class="r"><code>lm.fit = lm(lifeExp ~ gdpPercap_log)</code></pre>
<p>model fit의 결과를 보기위해 summary() 함수를 사용합니다.</p>
<pre class="r"><code>summary(lm.fit)
## 
## Call:
## lm(formula = lifeExp ~ gdpPercap_log)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -28.9571  -5.7319   0.7517   6.5770  13.7361 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    -17.846      5.067  -3.522 0.000578 ***
## gdpPercap_log   20.331      1.526  13.326  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.146 on 140 degrees of freedom
## Multiple R-squared:  0.5592, Adjusted R-squared:  0.556 
## F-statistic: 177.6 on 1 and 140 DF,  p-value: &lt; 2.2e-16</code></pre>
<div id="-------" class="section level3">
<h3>1. 기대수명은 일인당 국민소득과 연관이 있다고 말할 수 있을까요?</h3>
<p>위 질문에 답하기 위해 우리는 다음 두 가지를 하였습니다.<br />
1. fit a linear model 2. test the hypothesis: <span class="math inline">\(\beta_x\)</span> = 0</p>
<p>위 2번 가설 검정에 t-statistic 을 사용하였습니다. t statistic formula 는 아래와 같습니다.<br />
<span class="math display">\[t=\frac{\overline{x}-\mu_o}{SE}\]</span> <span class="math inline">\(\overline{x}\)</span>: sample mean (sample coefficient in linear regression) <span class="math inline">\(\mu_0\)</span>: population mean (population coefficient in linear regression) SE: standard error (of the coefficient in linear regression)</p>
</div>
<div id="---------" class="section level3">
<h3>2. 일인당 국민소득과 기대수명의 관계를 선형 모델로 얼마나 설명할 수 있을까요?</h3>
<p><span class="math display">\[R^2 = \frac{TSS - RSS}{TSS}\]</span><br />
- <span class="math inline">\(R^2\)</span>: the proportion of the total variation explained by the fit (regression model) - TSS: Total sum of squares (aka, SS around the mean) - RSS: Residual sum of squares (aka, SS around the fit)</p>
<p>[Note]<br />
<em>How different is the multiple R-squared from the Adjusted R-squared?</em><br />
The adjusted R-squared is a modified version of R-squared that has been adjusted for the number of predictors in the model. The adjusted R-squared increases only if the new term improves the model more than would be expected by chance. It decreases when a predictor improves the model by less than expected by chance. It is always lower than the R-squared.</p>
<dl>
<dt>F-statistic</dt>
<dd>the variance explained by the fit <strong>divided by</strong> the variance not explained by the fit
</dd>
</dl>
</div>
<div id="------------can-we-predict-accurately" class="section level3">
<h3>3. 우리는 선형모델을 이용해서 일인당 국민소득으로 기대 수명을 얼마나 정확하게 예측할 수 있을까? (Can we predict accurately?)</h3>
<p>앞에서 1952년 데이터를 이용해서 일인당 국민소득(정확히는 로그변환한)에서 기대수명을 예측하는 단순선형모델을 만들었습니다. 기대수명은 일인당 국민소득과 유의한 상관관계가 있으며, 단순 선형모델의 <span class="math inline">\(R^2\)</span>는 0.56, 즉 기대수명 변동의 56%가 이 모델로 설명된다는 것을 확인하였습니다.</p>
<p>이제, 1952년 데이터를 이용해 학습시킨 이 단순회귀 모델을 이용해 2002년 기대수명을 예측해봅시다.</p>
<pre class="r"><code>gapminder_2002 = gapminder %&gt;%
  filter(year == 2002) %&gt;%
  mutate(gdpPercap_log = log10(gdpPercap)) %&gt;%
  select(lifeExp, gdpPercap_log)</code></pre>
<p>예측값의 산출을 위해 predict() 함수를 사용합니다.</p>
<p>예측값과 실제 관측값이 얼마나 다른지 살펴봅시다.</p>
<pre class="r"><code>df = data.frame(observation = gapminder_2002$lifeExp, prediction = pred)
ggplot(df, aes(observation, prediction)) + geom_point() + geom_abline(slope = 1, intercept = 0)</code></pre>
<p><img src="DataMedicine_Lecture5_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>회귀모델의 예측 정확도를 나타내는 정량 지표로 RMSE (Root mean squared error)를 사용합니다.</p>
<p>MSE = variance = average SS not explained by the fit</p>
<pre class="r"><code>rmse = function(x){
  sqrt(sum((residuals(x)^2))/df.residual(x))
} # x = lm.fit </code></pre>
<pre class="r"><code>rmse(lm.fit) # gapminder_1952
## [1] 8.146311
rmse(lm(observation ~ prediction, df)) # gapminder 2002
## [1] 6.962083</code></pre>
<p>Confidence interval을 구해봅시다.</p>
</div>
</div>
<div id="classification" class="section level1">
<h1>분류(classification)</h1>
<p>classifier: assign a probability to each class</p>
<div id="logistic-regression" class="section level2">
<h2>logistic regression</h2>
<p>로지스틱 회귀는 회귀라는 이름을 가지고 있지만, 분류기로 광범위하게 사용됩니다. 분류 문제는 결국 결과 변수가 범주 변수일 때 결과가 특정 범주일 확률을 구하는 문제로 볼 수 있습니다.</p>
<p>먼저 odds 개념과 왜 log odds 를 사용하는지 알아봅시다.<br />
<a href="https://www.youtube.com/watch?v=ARfXDSkQf1Y">Odds and Log(Odds)</a></p>
<p>[from 3min][Logistic regression overview: Logit function](<a href="https://www.youtube.com/watch?v=yIYKR4sgzI8" class="uri">https://www.youtube.com/watch?v=yIYKR4sgzI8</a>)</p>
<p>logistic function <span class="math display">\[y = \frac{1}{1 + e^{-x}}\]</span> 로지스틱 함수의 출력값은 항상 0에서 1사이입니다. 시그모이드 모양을 가져서 시그모이드 함수라고 합니다.</p>
<p>우리가 범주가 2개인 분류 문제를 푼다고 하겠습니다.<br />
그리고, 아래와 같이 odds를 선형 함수로 모델링해보겠습니다.<br />
<span class="math display">\[\frac{P(X)}{1-P(X)} = \beta_0+\beta_1X\]</span></p>
<p>위 식에서 좌변은 0에서 무한대, 우변은 모든 값이 가능합니다. 양변의 범위가 맞지 않죠. 좌변에 log 를 취해 이 문제를 해결해봅시다. odd의 로그 변환을 logit 변환이라고 부릅니다.</p>
<p><span class="math display">\[\frac{P(X)}{1-P(X)} = e^{\beta_0+\beta_1X}\]</span></p>
<p>Logit <span class="math display">\[log(\frac{P(X)}{1-P(X)}) = \beta_0 + \beta_1X\]</span></p>
<p>위 식을 정리하면 다음과 같이 됩니다.<br />
<span class="math display">\[P(X) = \frac{1}{1+e^{-(\beta_0+\beta_1X)}}\]</span></p>
<p>가장 앞에서 보았던 로지스틱 함수가 됩니다. logistic regression은 결국 linear model의 일반화된 형태에 속하는 것입니다.</p>
<p><a href="https://www.youtube.com/watch?v=vN5cNN2-HWE">Logistic regression details part I, coefficients</a></p>
<p><a href="https://www.youtube.com/watch?v=XepXtl9YKwc">maximum likelihood estimation</a></p>
</div>
<div id="titanic-survival-classification" class="section level2">
<h2>titanic survival classification</h2>
<p>자, 이제 실습을 해봅시다.</p>
<pre class="r"><code>library(carData)</code></pre>
<pre class="r"><code>head(TitanicSurvival)
##                                 survived    sex     age passengerClass
## Allen, Miss. Elisabeth Walton        yes female 29.0000            1st
## Allison, Master. Hudson Trevor       yes   male  0.9167            1st
## Allison, Miss. Helen Loraine          no female  2.0000            1st
## Allison, Mr. Hudson Joshua Crei       no   male 30.0000            1st
## Allison, Mrs. Hudson J C (Bessi       no female 25.0000            1st
## Anderson, Mr. Harry                  yes   male 48.0000            1st
str(TitanicSurvival)
## &#39;data.frame&#39;:    1309 obs. of  4 variables:
##  $ survived      : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 2 2 1 1 1 2 2 1 2 1 ...
##  $ sex           : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 1 2 1 2 1 2 1 2 1 2 ...
##  $ age           : num  29 0.917 2 30 25 ...
##  $ passengerClass: Factor w/ 3 levels &quot;1st&quot;,&quot;2nd&quot;,&quot;3rd&quot;: 1 1 1 1 1 1 1 1 1 1 ...
summary(TitanicSurvival)
##  survived      sex           age          passengerClass
##  no :809   female:466   Min.   : 0.1667   1st:323       
##  yes:500   male  :843   1st Qu.:21.0000   2nd:277       
##                         Median :28.0000   3rd:709       
##                         Mean   :29.8811                 
##                         3rd Qu.:39.0000                 
##                         Max.   :80.0000                 
##                         NA&#39;s   :263</code></pre>
<p>타이타닉호의 생존 데이터입니다. 생존 여부를 예측하는 분류 문제를 다루어봅시다.</p>
<p>missing data point 가 있군요(age, NA’s). 해당 observation은 제거하기로 합시다.</p>
<pre class="r"><code>TitanicSurvival = TitanicSurvival[complete.cases(TitanicSurvival),]</code></pre>
<p>다음으로 logistic regression model을 데이터에 적합시켜봅시다(fit).</p>
<pre class="r"><code>glm.fit = glm(survived ~., data = TitanicSurvival, family = &quot;binomial&quot;)</code></pre>
<p>logistic regression model fit 의 결과를 해석해봅시다.</p>
<pre class="r"><code>summary(glm.fit)
## 
## Call:
## glm(formula = survived ~ ., family = &quot;binomial&quot;, data = TitanicSurvival)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.6399  -0.6979  -0.4336   0.6688   2.3964  
## 
## Coefficients:
##                    Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)        3.522074   0.326702  10.781  &lt; 2e-16 ***
## sexmale           -2.497845   0.166037 -15.044  &lt; 2e-16 ***
## age               -0.034393   0.006331  -5.433 5.56e-08 ***
## passengerClass2nd -1.280570   0.225538  -5.678 1.36e-08 ***
## passengerClass3rd -2.289661   0.225802 -10.140  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1414.62  on 1045  degrees of freedom
## Residual deviance:  982.45  on 1041  degrees of freedom
## AIC: 992.45
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>남자는 여자보다 생존할 확률이 큽니까? 얼마나 큽니까?</p>
<pre class="r"><code>exp(coef(glm.fit)[2])
##    sexmale 
## 0.08226211</code></pre>
<p>male 인 경우 female 에 비해서, 생존/죽음 odds가 0.08배 (즉, 훨씬 낮다, 10배 이상), Odds ratio 개념…</p>
<p>독립 변수가 범주형 변수일 때, 회귀 모델에서는 이를 dummy variable로 변환합니다.</p>
<pre class="r"><code>contrasts(TitanicSurvival$survived)
##     yes
## no    0
## yes   1
contrasts(TitanicSurvival$passengerClass)
##     2nd 3rd
## 1st   0   0
## 2nd   1   0
## 3rd   0   1</code></pre>
</div>
<div id="classification-model-accurancy" class="section level2">
<h2>Classification model accurancy</h2>
<p>앞에서 회귀 문제에서는 모델의 정확도는 RMSE 로 평가한다고 했습니다.<br />
분류 문제에서는 모델의 정확도를 어떻게 평가할까요?</p>
<p>먼저, 위에서 만든 모델을 사용하여 타이타닉호의 생존 결과를 예측해봅시다.</p>
<pre class="r"><code>glm.probs = predict(glm.fit, type = &quot;response&quot;)</code></pre>
<p><a href="https://www.youtube.com/watch?v=Kdsp6soqA7o">Confusion matrix</a></p>
<p>자, 그럼 classification prediction accuracy를 계산해봅시다.</p>
<pre class="r"><code>glm.pred = rep(&quot;no&quot;, length(glm.probs))
glm.pred[glm.probs&gt;0.5] = &quot;yes&quot;
table(glm.pred, TitanicSurvival$survived)
##         
## glm.pred  no yes
##      no  520 126
##      yes  99 301
mean(glm.pred == TitanicSurvival$survived)
## [1] 0.7848948</code></pre>
<p>위의 예제는 training data 에서 성능을 평가한 것이고, 우리가 실제로 관심이 있는 것은 모델 훈련에 사용되지 않은 새로운 데이터셋에서의 성능일겁니다. 아래는 전체 데이터셋을 training set 과 test set 으로 나누고, training set에서 만든 모델을 test set에 적용해 성능을 평가한 것입니다.</p>
<pre class="r"><code>set.seed(1)
index = sample(1:1046, round(1046/7), replace = F)
train.data = TitanicSurvival[index,]
test.data = TitanicSurvival[-index,]</code></pre>
<p>fit the model with training data, and predict in test data</p>
<pre class="r"><code>glm.fit = glm(survived ~., data = train.data, 
              family = &quot;binomial&quot;)
glm.probs = predict(glm.fit, test.data, type = &quot;response&quot;)</code></pre>
<p>confusion matrix &amp; accuray</p>
<pre class="r"><code>glm.pred = rep(&quot;no&quot;, 1046-round(1046/7))
glm.pred[glm.probs&gt;0.5] = &quot;yes&quot;
table(glm.pred, test.data$survived)
##         
## glm.pred  no yes
##      no  447 115
##      yes  84 251
mean(glm.pred == test.data$survived)
## [1] 0.7781494</code></pre>
</div>
<div id="linear-discrminant-analysis-lda" class="section level2">
<h2>Linear discrminant analysis (LDA)</h2>
<p>로지스틱 회귀는 로지스틱 함수를 이용하여 두 개의 반응 변수 클래스에 대해 <span class="math inline">\(Pr(Y=k|X=x)\)</span>를 직접 모델링한다.</p>
<p>이제 LDA라고 불리는 대안 기법에 대해 알아보자.</p>
<p>LDA에서는 반응 변수 Y의 각 클래스내의 관측치들이 클래스 별로 평균(<span class="math inline">\(\mu_k\)</span>)과 클래스 공통 분산(<span class="math inline">\(\sigma^2\)</span>)을 갖는 정규분포를 따른다는 가정하에 이 파라미터에 대한 추정값을 베이즈 분류기에 대입한 것이다.</p>
<p>베이즈 뷘류기(Bayes classifier)는 설명변수 X가 <span class="math inline">\(x\)</span>로 주어졌을 때 반응변수 Y가 <span class="math inline">\(k\)</span> 클래스일 확률을 베이즈 정리를 이용해 구하고, 이에 따라 관측치를 분류한다.</p>
<p><span class="math display">\[P(Y=k|X=x)\]</span></p>
<p>베이즈 정리(Bayes theorem)를 기억하자.<br />
<span class="math display">\[P(B|A) = \frac{P(A|B)\times P(B)}{P(A)}\]</span></p>
<p>베이즈 정리를 베이즈 분류기에 적용하면 아래 식이 된다.<br />
<span class="math display">\[P(Y=k|X=x) = \frac{P(X=x|Y=k) \times P(Y=k)}{\sum_{l=1}^k P(X=x|Y=l)} \]</span></p>
<p>위 베이즈 정리가 의미하는 것은 <span class="math inline">\(P(Y=k|X=x)\)</span> - 사후 확률이라고 한다 - 를 직접 계산하는 대신에 <span class="math inline">\(P(Y=k)\)</span>와 <span class="math inline">\(P(X=x|Y=k)\)</span> - 사전 확률 - 의 추정치를 통해 구할 수 있다는 것이다.</p>
<p><span class="math inline">\(P(Y=k)\)</span> 추정은 쉽다. 즉, k번째 클래스에 속하는 관측치들의 비율을 단순히 계산하면 된다.</p>
<p>하지만, <span class="math inline">\(P(X=x|Y=k)\)</span>에 대한 추정은 어떤 분포를 가정하지 않는다면 어렵다. LDA는 사전확률을 추정하기 위해 아래와 같은 가정을 한다.</p>
<p>Assumptions in LDA<br />
- normal distribution of <span class="math inline">\(P(X=x|Y=k)\)</span><br />
- common variance across different k class</p>
<p>이제 우리는 k 클래스에 속한 관측치의 평균과 분산(공통)을 구해 확률밀도함수 <span class="math inline">\(P(X=x|Y=k)\)</span>를 추정할 수 있고, 결국 <span class="math inline">\(P(Y=k|X=x)\)</span>도 추정할 수 있다. (정규분포의 확률밀도함수 참조)</p>
<p>Calculate posterior probability with…<br />
- P(Y=k): proportion<br />
- <span class="math inline">\(\mu_k: mean(X)\ in\ class\ k\)</span><br />
- <span class="math inline">\(\sigma^2: variance\)</span></p>
<p>최종적으로 얻어지는 분류기는 다음 식을 최대로 하는 클래스에 관측치를 할당하는 것과 동일하다.<br />
<span class="math display">\[\hat{\delta_k} = x\times\frac{\hat{\mu_k}}{\hat{\sigma}^2}-\frac{\hat{\mu_k}^2}{2\hat{\sigma}^2}+log(\hat{\pi_k})\]</span> 여기서 <span class="math inline">\(\delta_k\)</span>는 linear disciminant function 이라고 한다. 분류기 이름에 선형이라는 말이 있는 것은 위 판별함수가 x의 선형함수이기 때문이다.</p>
<p><strong>figure</strong> <img src="img/LDA.png" style="border: #A9A9A9 1px solid; width:75%"></p>
<p>LDA는 나중에 살펴볼 PCA (principal component analysis)와 매우 유사하다. 미리 어떤 유사점과 차이점이 있는지 알아보자.</p>
<p><a href="https://www.youtube.com/watch?v=azXCzI57Yfc">LDA &amp; PCA</a></p>
<p>로지스틱 회귀 vs. LDA<br />
1. 클래스의 수가 2보다 많은 반응 변수를 분류해야 할 때가 있다. 다중 로지스틱회귀 모델이 있지만 실제로는 자주 사용되지 않는다.<br />
2. 클래스들이 잘 분리될 때 로지스틱 회귀모델에 대한 모수 추정치는 아주 불안정하다. 선형판별분석은 이런 문제가 없다.<br />
3. 만약 n이 작고, 각 클래스에서 설명변수 X의 분포가 근사적으ㄹ 정규분포이면 선형판별모델이 로지스틱회귀모델보다 더 안정적이다.</p>
</div>
<div id="lda-" class="section level2">
<h2>LDA 실습</h2>
<p>다시 titanic 호로 돌아와보자.<br />
fit LDA to training data</p>
<pre class="r"><code>library(MASS)
## 
## Attaching package: &#39;MASS&#39;
## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<pre class="r"><code>lda.fit = lda(survived~., data = train.data)</code></pre>
<p>LDA fit 결과를 살펴보자.</p>
<pre class="r"><code>lda.fit
## Call:
## lda(survived ~ ., data = train.data)
## 
## Prior probabilities of groups:
##       no      yes 
## 0.590604 0.409396 
## 
## Group means:
##       sexmale      age passengerClass2nd passengerClass3rd
## no  0.8636364 29.67992         0.2954545         0.5909091
## yes 0.2459016 31.13934         0.2622951         0.2950820
## 
## Coefficients of linear discriminants:
##                            LD1
## sexmale           -2.248264867
## age               -0.008963284
## passengerClass2nd -0.910193062
## passengerClass3rd -1.186282087</code></pre>
<p>각 클래스에서 LD 값의 분포를 알고 싶다면…</p>
<pre class="r"><code>plot(lda.fit)</code></pre>
<p><img src="DataMedicine_Lecture5_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>위에서 만든 LDA 모델을 이용해 test data에서 생존 결과를 예측해보자.</p>
<pre class="r"><code>lda.pred = predict(lda.fit, test.data)</code></pre>
<pre class="r"><code>names(lda.pred)
## [1] &quot;class&quot;     &quot;posterior&quot; &quot;x&quot;</code></pre>
<p>confusion matrix</p>
<pre class="r"><code>table(lda.pred$class, test.data$survived)
##      
##        no yes
##   no  447 120
##   yes  84 246</code></pre>
<p>예측 정확도는 얼마인가? 로지스틱회귀모델과 비교하면 성능이 어떠한가?</p>
<pre class="r"><code>mean(lda.pred$class == test.data$survived)
## [1] 0.7725753</code></pre>
</div>
<div id="k-nearest-neighbor-knn" class="section level2">
<h2>k-nearest neighbor (KNN)</h2>
<p>KNN은 어떤 관측치의 클래스를 결정할 때, K개의 근접한 이웃의 클래스들이 무엇인지에 따라, 즉 majortity vote의 결과로 해당 관측치의 클래스를 결정하는 알고리즘입니다.</p>
<p><a href="https://www.youtube.com/watch?v=HVXime0nQeI">KNN</a></p>
<p>그럼, 바로 실습해봅시다.</p>
<pre class="r"><code>library(class) # knn</code></pre>
<p>dummy variables</p>
<pre class="r"><code>library(dummies)
## dummies-1.5.6 provided by Decision Patterns</code></pre>
<pre class="r"><code>TitanicSurvival = cbind(TitanicSurvival, dummy(TitanicSurvival$sex), dummy(TitanicSurvival$passengerClass))
TitanicSurvival.dummy = TitanicSurvival[,c(1,3,5:9)]</code></pre>
<pre class="r"><code>train.knn = TitanicSurvival.dummy[index,]
test.knn = TitanicSurvival.dummy[-index,]</code></pre>
<pre class="r"><code>train.x = train.knn[,-1]
train.y = train.knn[,1]
test.x = test.knn[,-1]
test.y = test.knn[,1]</code></pre>
<pre class="r"><code>knn.pred = knn(train = train.x, cl = train.y, test = test.x, k=3)</code></pre>
<pre class="r"><code>table(knn.pred, test.y)
##         test.y
## knn.pred  no yes
##      no  398 173
##      yes 133 193
mean(knn.pred == test.y)
## [1] 0.6588629</code></pre>
</div>
<div id="roc-curve" class="section level2">
<h2>ROC curve</h2>
<p><a href="https://www.youtube.com/watch?v=4jRBRDbJemM">ROC</a></p>
<p><strong>figure</strong> <img src="img/ROC.png" style="border: #A9A9A9 1px solid; width:75%"></p>
<p>Load the ROCR library</p>
<pre class="r"><code>library(ROCR)
## Loading required package: gplots
## 
## Attaching package: &#39;gplots&#39;
## The following object is masked from &#39;package:stats&#39;:
## 
##     lowess</code></pre>
<pre class="r"><code>probs.glm = predict(glm.fit, test.data, type = &quot;response&quot;)</code></pre>
<p>Make a prediction object: pred</p>
<pre class="r"><code>pred = prediction(probs.glm, test.data$survived)</code></pre>
<p>Make a performance object: perf</p>
<pre class="r"><code>perf1 = performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)</code></pre>
<p>Plot ROC curve</p>
<pre class="r"><code>plot(perf1)</code></pre>
<p><img src="DataMedicine_Lecture5_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<p>Print out the AUC</p>
<pre class="r"><code>perf2 = performance(pred, &quot;auc&quot;)
str(perf2)
## Formal class &#39;performance&#39; [package &quot;ROCR&quot;] with 6 slots
##   ..@ x.name      : chr &quot;None&quot;
##   ..@ y.name      : chr &quot;Area under the ROC curve&quot;
##   ..@ alpha.name  : chr &quot;none&quot;
##   ..@ x.values    : list()
##   ..@ y.values    :List of 1
##   .. ..$ : num 0.835
##   ..@ alpha.values: list()
perf2@y.values[[1]]
## [1] 0.8349027</code></pre>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
