---
title: "기계학습의 기초"
output:
  html_document:
    toc: yes
    toc_float: true
---

# 기계학습(Machine Learning)   

## 기계학습이란 무엇인가?   
기계학습은 지도 기계학습과 비지도 기계학습으로 구분한다. 지도 기계학습은 입력 변수를 기반으로 출력 변수를 예측하는 모델을 만드는 것이고, 비지도 기계학습은 출력 변수 없이 입력 변수만 가지고 자료의 상관 관계와 구조를 파악하는 것과 관련이 있다 (cluster analysis).  

출력 변수는 반응 변수, 응답 변수, 또는 종속 변수라고 불리며 보통 $Y$를 사용하여 나타낸다.   

입력 변수는 보통 $X$로 나타내고, 아래 첨자를 사용하여 서로 다른 입력 변수들을 구분한다. 입력 변수는 설명 변수, 예측 변수, 독립 변수, 특징(features) 또는 그냥 변수라고 불린다.  

$X$와 $Y$의 관계를 다음 식으로 나타낼 수 있다.  

> $Y$ = f($X$) + $e$  

$X$ = $X_1$ + $X_2$ + ... + $X_p$; predictors, independent variables, features, variables  
$Y$; response variable, dependent variable   
$e$; random error term (independent of $X$, mean = 0)

위에서 f는 어떤 함수이고, 지도 기계학습은 이 f를 추정하는 일련의 과정을 말하는 것이다.   


## $f$를 추정하는 이유는 무엇인가? Why estimate $f$? 

f를 어떻게 추정하는지 하는 방법을 구체적으로 살펴보기에 앞서, 우선 f를 추정하고자 하는 목적, 이유에 대해 살펴보자. 크게 두가지로 구분해 볼 수 있는데, 그것은 바로 예측과 추론이다.  

1. prediction    

$$\hat{Y} = \hat{f}(X)$$

$\hat{Y}$은 Y에 대한 예측 결과를 나타내며, $\hat{f}$은 f에 대한 추정을 나타낸다.  

예측 문제에서 $\hat{f}$는 보통 블랙박스로 취급된다. $\hat{f}$가 정확한 예측을 제공한다면 그것의 정확한 형태에 대해서는 통상 관심이 없기 때문이다.  

$\hat{Y}$의 정확성은 오차를 얼마나 줄일 수 있느냐에 달려있다. 오차는 크게 축소가능한 오차와 축소불가능한 오차로 구분할 수 있다. 

축소가능 오차(reducible error): 가장 적절한 기계학습 기법을 사용하여 f를 추정함으로써 $\hat{f}$의 정확성을 개선할 수 있다.   

축소불가능 오차(irreducible error): 근본적으로 측정할 수 없는 변동성이나, 혹은 측정되지 않은 유용한 변수들에 대한 오차를 말한다.  

축소불가능 오차는 예측 정확도의 상한선이 되겠지만, 그 경계는 현실적으로 거의 언제나 알려져 있지 않다. 우리는 축소가능 오차를 최대한 줄이는 f를 추정하는 기법들에 대해 다룬다.   
  
2. inference   

추론은 X가 변함에 따라 Y가 어떻게 영향을 받는지를 이해하는데 관심이 있다. 따라서, $\hat{f}$는 블랙박스로 취급될 수 없다. 그것의 정확한 형태를 알아야 할 필요가 있기 때문이다.   

- which predictors are associated with the response?  
- what is the relationship between the response and each predictor?   
- Can the relationship between Y and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?   
[Challenges]  
의학, 의료 분야에서 기계학습을 이용한 예측과 추론 문제의 예를 들어보자.    

## 어떻게 f를 추정하는가? how to estimate the function $f$?  

훈련 데이터를 이용하여 f를 추정하는데, 이를 위한 기계학습 기법들은 크게 모수적 방법과 비모수적 방법으로 나누어 볼 수 있다.   

1. parametric methods  

  - assume about the functional form (model-based)  
  - fit the model by using the data (training) (ex. least squares) 
모수적 방법은 두 단계로 구성된 모델 기반의 방법이다.  
우선, f의 함수 형태에 대해 가정한다. 예를 들면, 아주 단순하게 Y는 X에 대해 선형 관계라고 가정한다.  

$$f(X) = \beta_0 + \beta_1X_1 + \beta_2X_2 + ...+\beta_pX_p$$

다음으로 훈련데이터를 이용하여 모델을 적합(fit)하는 절차가 필요하다. 즉, 위 선형 모델의 경우, 파라미터 집합 $\beta_0$, $\beta_1$, $\beta_2$,..., $\beta_p$을 추정하는 절차이며, 선형 모델의 적합에 가장 일반적으로 사용되는 기법은 최소제곱(least squares)이다.     

[중요]  
과적합(overfitting)이란 오차를 너무 면밀히 추적하는 것을 말한다. 일반적으로 모수적 방법에서 가정한 모델이 유연하고 복잡할 수록 (spline model > linear model) 과적합의 위험은 커진다. 

**figure**  
<img src="img/least_flexible_model.png" style="border: #A9A9A9 1px solid; width:75%">
<img src="img/flexible_model.png" style="border: #A9A9A9 1px solid; width: 75%">
<img src="img/very_flexible_model.png" style="border: #A9A9A9 1px solid; width: 75%"> 

2. non-parametric methods

  - not assume about the functional form of $f$   
  - estimate $f$ that gets as close to data points as possible w/o being too much wiggly   

[Challenge]  
모수적 방법과 비모수적 방법의 장,단점에 대해 생각해봅시다.   


## Model flexibility & Interpretability 

[Challenge]  
일반적으로 덜 유연한(e.g., linear) 모델을 더 유연한 모델(e.g., spline)보다 선호할 수 있는데, 그 이유는 무엇일까?    

 
**figure** 모델의 유연성과 해석력 사이의 관계   
<img src="img/flexibility_interpretability.png" style="border: #A9A9A9 1px solid; width: 75%">

우리가 추론에는 관심이 없고, 예측에만 관심이 있다면 가장 유연한 모델을 사용하는 것이 최선이라고 예상할 수 있다. 그러나, 놀랍게도 이것이 항상 맞는 것은 아니다! 우리는 종종 덜 유연한 방법을 사용하여 더 정확한 예측을 얻을 것이다. 직관에 반하는 것처럼 보이는 이러한 현상은 아주 유연한 방법들의 잠재적인 과적합 문제와 관련이 있다.    

## 회귀와 분류 (Regression vs. Classification)  

whether the response variable is quantitative (regression) or qualitative (classification) 

## 모델의 정확도 평가 (How to asess the accuracy of model?)  

기계학습 모델의 성능 평가에 대해 말하기에 앞서, 모든 자료에 대해 가장 좋은 결과를 줄 수 있는 단 하나의 방법(master algorithm)은 없을까 생각해보자. 결론부터 말하자면, 그러한 기법은 없다. 이것이 우리가 앞으로 여러가지 기계학습 기법을 살펴보는 이유이다. 이것은 공짜 점심은 없다는 이론과 관계가 있다.   

**Note** 
*No free lunch theorem* Selecting the best approach can be one of the most challenging parts of performing statistical learning in practice.

### 회귀 (Regression)  

기계학습 모델의 성능을 평가한다는 것은 예측치와 관측치가 얼마나 잘 맞는지 측정한다는 것이다. 회귀 문제에서 가장 일반적으로 사용되는 척도는 아래 식으로 주어지는 평균제곱오차이다.   

mean squared error (MSE)

$$MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2$$
training data를 이용하여 계산한 MSE는 training MSE 라고 한다. 우리는 그러나 일반적으로 기계학습 모델이 training data에서 얼마나 잘 작동하는지에는 관심이 없다. 실제로 관심이 있는 것은 test data에 적용할 때 없는 예측 정확도이다 (test MSE).   

### 분류 (Classification)

분류 문제에서 분류기 $\hat{f}$의 정확도를 수량화하는 가장 흔한 지표는 아래 식으로 주어지는 오차율이다. 

error rate

$$\frac{1}{n}\sum_{i=1}^{n}I(y_i \neq \hat{y_i})$$
$\hat{y_i}$는 $\hat{f}$를 사용하여 예측된 i번째 관측치에 대한 클래스 표시(label)이고,   
$I(y_i \neq \hat{y_i})$는 indicator variable로 $y_i \neq \hat{y_i}$이면 1이고, $y_i = \hat{y_i}$이면 0이다. 

## 편향 분산 절출 (Bias-Variance trade-off)  

Bias: error   
Variance: how much the $\hat{f}$ changes with different training data sets   

> As a general rule, as we use more flexible methods, the variance will increase and the bias will decrease

*figure*
<img src="img/bias_variance_tradeoff.png" style="border: #A9A9A9 1px solid; width:75%">  
   
<img src="img/knn_bias_variance_tradeoff.png" style="border: #A9A9A9 1px solid; width:75%">

> The challenge lies in finding a method for which both the variance and the bias are low.

## 실습 문제  

1. For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.
(a) The sample size n is extremely large, and the number of predic- tors p is small.
(b) The number of predictors p is extremely large, and the number of observations n is small.
(c) The relationship between the predictors and response is highly non-linear.
(d) The variance of the error terms, i.e. σ2 = Var(ε), is extremely high.
<br>

2. Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p.
(a) We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.
(b) We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each prod- uct we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.
(c) We are interesting in predicting the % change in the US dollar in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the dollar, the % change in the US market, the % change in the British market, and the % change in the German market.
<br> 


3. You will now think of some medical applications for machine learning.  
(a) Describe three real-life applications in which classification might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.
(b) Describe three real-life applications in which regression might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.
(c) Describe three real-life applications in which cluster analysis might be useful.
<br> 

4. What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred?
<br> 

5. Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a para- metric approach to regression or classification (as opposed to a non- parametric approach)? What are its disadvantages?
<br> 

6. The table below provides a training data set containing six observa- tions, three predictors, and one qualitative response variable.

Obs.|$X_1$|$X_2$|$X_3$|$Y$
--- | --- | --- | --- | ---
1|0|3|0|Red  
2|2|0|0|Red  
3|0|1|3|Red  
4|0|1|2|Green  
5|-1|0|1|Green  
6|1|1|1|Red  
  
Suppose we wish to use this data set to make a prediction for Y when X1 = X2 = X3 = 0 using K-nearest neighbors.
(a) Compute the Euclidean distance between each observation and thetestpoint,X1 =X2 =X3 =0.

(b) What is our prediction with K = 1? Why?
(c) What is our prediction with K = 3? Why?
(d) If the Bayes decision boundary in this problem is highly non- linear, then would we expect the best value for K to be large or small? Why?







