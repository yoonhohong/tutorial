<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Regularization</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 64px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h2 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h3 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h4 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h5 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h6 {
  padding-top: 69px;
  margin-top: -69px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Tutorial</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="https://yoonhohong.github.io">by Yoon H. Hong</a>
</li>
<li>
  <a href="http://www.github.com/yoonhohong/tutorial">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Regularization</h1>

</div>


<div id="curse-of-dimensionality" class="section level1">
<h1>Curse of dimensionality</h1>
<p>in circumstances of p &gt;&gt; n<br />
using all the features to predict response variable<br />
will face two drawbacks in terms of …<br />
- interpretability<br />
- increase of variance (overfitting)<br />
</br></p>
<p>so, we do<br />
feature selection<br />
- subset selection<br />
- shrinkage (regularization)<br />
- dimension reduction</p>
</div>
<div id="subset-selection" class="section level1">
<h1>Subset selection</h1>
<p>가능한 경우의 수: <span class="math inline">\(2^p\)</span><br />
stepwise selection: forward, backward</p>
</div>
<div id="shrinkage" class="section level1">
<h1>Shrinkage</h1>
<p><a href="https://www.youtube.com/watch?v=Q81RR3yKn30">Ridge regression</a> <a href="https://www.youtube.com/watch?v=NGf0voTMlcs">Lasso regression</a> <a href="https://www.youtube.com/watch?v=1dKRdX9bfIo">Elastic-net regression</a></p>
<p>아래 식을 최소로 하는 <span class="math inline">\(\beta\)</span> 를 추정 (note: shrinkage penalty)<br />
ridge regresssion<br />
<span class="math display">\[RSS + \lambda \sum_{j=1}^{p} \beta^2_j\]</span><br />
<span class="math inline">\(\lambda\)</span>: tuning parameter</p>
<p>lasso regression<br />
<span class="math display">\[RSS + \lambda \sum_{j=1}^{p} |\beta_j|\]</span></p>
<pre class="r"><code>library(glmnet)</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## Loaded glmnet 2.0-16</code></pre>
<pre class="r"><code>x = model.matrix(Salary~., Hitters)[,-1] # create a matrix, convert factors to a set of dummy variables  
y = Hitters$Salary</code></pre>
<pre class="r"><code>grid = 10^seq(10, -2, length = 100) # lambda 를 10^10 에서 10^-2 까지 값을 갖도록 설정 </code></pre>
<pre class="r"><code>ridge.mod = glmnet(x,y,alpha = 0, lambda = grid) # alpha = 0 for ridge regression, alpha = 1 for lasso regression 
?glmnet # standardize = TRUE </code></pre>
<pre class="r"><code>plot(ridge.mod)</code></pre>
<p><img src="DataMedicine_Lecture8_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>L2 norm: <span class="math inline">\(\sqrt{\sum_{j=1}^{p}\beta^2_j}\)</span></p>
<pre class="r"><code>coef(ridge.mod)</code></pre>
<pre class="r"><code>ridge.mod$lambda</code></pre>
<pre class="r"><code>ridge.mod$lambda[50]</code></pre>
<pre><code>## [1] 11497.57</code></pre>
<pre class="r"><code>coef.50lambda = coef(ridge.mod)[-1,50] # at 50th lambda, coefficients
sqrt(sum(coef.50lambda^2)) # L2 norm at 50th lambda </code></pre>
<pre><code>## [1] 6.360612</code></pre>
<pre class="r"><code>set.seed(1)
train = sample(nrow(x), nrow(x)/2)
y.test = y[-train]</code></pre>
<p>arbitrary set lamda = 4</p>
<pre class="r"><code>ridge.mod = glmnet(x[train,], y[train], alpha = 0, lambda = grid)
ridge.pred = predict(ridge.mod, s=4, newx = x[-train,])
mean((ridge.pred-y.test)^2)</code></pre>
<pre><code>## [1] 101186.3</code></pre>
<p>cv 를 통해 검정오차 추정치가 가장 낮은 lambda 값을 구함</p>
<pre class="r"><code>set.seed(1)
cv.out.ridge = cv.glmnet(x[train,], y[train], alpha = 0) # nfolds = 10 
plot(cv.out.ridge)</code></pre>
<p><img src="DataMedicine_Lecture8_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>bestlambda.ridge = cv.out.ridge$lambda.min
bestlambda.ridge</code></pre>
<pre><code>## [1] 211.7416</code></pre>
<p>cv 검정오차 추정치가 가장 낮은 lambda 값을 이용하여 검정셋에서 검정오차를 구함</p>
<pre class="r"><code>ridge.pred = predict(ridge.mod, s=bestlambda.ridge, newx = x[-train,])
mean((ridge.pred - y.test)^2)</code></pre>
<pre><code>## [1] 96012.47</code></pre>
<p>전체 데이터셋에서 ridge regression 모델을 만들고, 해당 coefficients 값을 구함</p>
<pre class="r"><code>ridge.out = glmnet(x,y,alpha = 0)
predict(ridge.out, type = &quot;coefficients&quot;, s=bestlambda.ridge)</code></pre>
<pre><code>## 20 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                        1
## (Intercept)   9.88487157
## AtBat         0.03143991
## Hits          1.00882875
## HmRun         0.13927624
## Runs          1.11320781
## RBI           0.87318990
## Walks         1.80410229
## Years         0.13074383
## CAtBat        0.01113978
## CHits         0.06489843
## CHmRun        0.45158546
## CRuns         0.12900049
## CRBI          0.13737712
## CWalks        0.02908572
## LeagueN      27.18227527
## DivisionW   -91.63411282
## PutOuts       0.19149252
## Assists       0.04254536
## Errors       -1.81244470
## NewLeagueN    7.21208394</code></pre>
<p>lasso</p>
<pre class="r"><code>lasso.mod = glmnet(x[train,], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)</code></pre>
<p><img src="DataMedicine_Lecture8_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<pre class="r"><code>set.seed(1)
cv.lasso.out = cv.glmnet(x[train,], y[train], alpha=1)
plot(cv.lasso.out)</code></pre>
<p><img src="DataMedicine_Lecture8_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<pre class="r"><code>bestlambda.lasso = cv.lasso.out$lambda.min
lasso.pred = predict(lasso.mod, s=bestlambda.lasso, newx = x[-train,])
mean((lasso.pred - y.test)^2)</code></pre>
<pre><code>## [1] 100743.4</code></pre>
<pre class="r"><code>lasso.out = glmnet(x,y,alpha = 1, lambda = grid)
lasso.coef = predict(lasso.out, type = &quot;coefficients&quot;, s=bestlambda.lasso)
lasso.coef</code></pre>
<pre><code>## 20 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                        1
## (Intercept)   18.5394844
## AtBat          .        
## Hits           1.8735390
## HmRun          .        
## Runs           .        
## RBI            .        
## Walks          2.2178444
## Years          .        
## CAtBat         .        
## CHits          .        
## CHmRun         .        
## CRuns          0.2071252
## CRBI           0.4130132
## CWalks         .        
## LeagueN        3.2666677
## DivisionW   -103.4845458
## PutOuts        0.2204284
## Assists        .        
## Errors         .        
## NewLeagueN     .</code></pre>
<p>linear regression</p>
<pre class="r"><code>lm.fit = lm(Salary~., data = Hitters, subset = train)
lm.pred = predict(lm.fit, newdata = Hitters[-train,])
mean((lm.pred - y.test)^2)</code></pre>
<pre><code>## [1] 114780.6</code></pre>
</div>
<div id="dimension-reduction" class="section level1">
<h1>Dimension reduction</h1>
<ul>
<li>principal component regression (PCR)<br />
</li>
<li>partial least square (PLS)</li>
</ul>
<p>p개의 설명변수들을 m개의 (m<p) 새로운 변수로 변환하고, 변환된 변수들을 사용해 최소제곱모델을 적합하는 기법   

PCA (-> PCR) : 설명변수들의 <em>정규화</em>된 선형결합<br />
: 분산이 가장 큰 방향 (첫번째 주성분)</p>
<dl>
<dt>PLS</dt>
<dd>PCA의 supervised version
</dd>
<dd>반응변수와 극대화된 상관관계를 갖도록 선형결합
</dd>
</dl>
<pre class="r"><code>library(pls)</code></pre>
<pre><code>## 
## Attaching package: &#39;pls&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     loadings</code></pre>
<pre class="r"><code>set.seed(2)
pcr.fit = pcr(Salary~., data = Hitters, subset = train, scale = TRUE, validation = &quot;CV&quot;)
summary(pcr.fit)</code></pre>
<pre><code>## Data:    X dimension: 131 19 
##  Y dimension: 131 1
## Fit method: svdpc
## Number of components considered: 19
## 
## VALIDATION: RMSEP
## Cross-validated using 10 random segments.
##        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
## CV           464.6    399.3    400.5    402.3    407.0    396.6    397.6
## adjCV        464.6    398.8    399.6    401.2    405.4    395.9    394.4
##        7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
## CV       395.3    396.3    400.1     413.3     413.9     417.0     416.9
## adjCV    393.3    394.0    397.6     410.2     410.7     413.7     413.2
##        14 comps  15 comps  16 comps  17 comps  18 comps  19 comps
## CV        413.1     414.6       414     402.3     396.8     399.2
## adjCV     409.4     410.9       410     398.3     392.7     395.0
## 
## TRAINING: % variance explained
##         1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
## X         38.89    60.25    70.85    79.06    84.01    88.51    92.61
## Salary    28.44    31.33    32.53    33.69    36.64    40.28    40.41
##         8 comps  9 comps  10 comps  11 comps  12 comps  13 comps  14 comps
## X         95.20    96.78     97.63     98.27     98.89     99.27     99.56
## Salary    41.07    41.25     41.27     41.41     41.44     43.20     44.24
##         15 comps  16 comps  17 comps  18 comps  19 comps
## X          99.78     99.91     99.97    100.00    100.00
## Salary     44.30     45.50     49.66     51.13     51.18</code></pre>
<pre class="r"><code>validationplot(pcr.fit, val.type = &quot;MSEP&quot;)</code></pre>
<p><img src="DataMedicine_Lecture8_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<pre class="r"><code>pcr.pred = predict(pcr.fit, x[-train,], ncomp = 2)
mean((pcr.pred - y.test)^2)</code></pre>
<pre><code>## [1] 97563.65</code></pre>
<pre class="r"><code>pcr.fit = pcr(y~x, scale = TRUE, ncomp = 2)
summary(pcr.fit)</code></pre>
<pre><code>## Data:    X dimension: 263 19 
##  Y dimension: 263 1
## Fit method: svdpc
## Number of components considered: 2
## TRAINING: % variance explained
##    1 comps  2 comps
## X    38.31    60.16
## y    40.63    41.58</code></pre>
<p>PLS</p>
<pre class="r"><code>set.seed(1)
pls.fit = plsr(Salary~., data = Hitters, subset = train, scale = TRUE, validation = &quot;CV&quot;)
summary(pls.fit)</code></pre>
<pre><code>## Data:    X dimension: 131 19 
##  Y dimension: 131 1
## Fit method: kernelpls
## Number of components considered: 19
## 
## VALIDATION: RMSEP
## Cross-validated using 10 random segments.
##        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
## CV           464.6    394.2    391.5    393.1    395.0    415.0    424.0
## adjCV        464.6    393.4    390.2    391.1    392.9    411.5    418.8
##        7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
## CV       424.5    415.8    404.6     407.1     412.0     414.4     410.3
## adjCV    418.9    411.4    400.7     402.2     407.2     409.3     405.6
##        14 comps  15 comps  16 comps  17 comps  18 comps  19 comps
## CV        406.2     408.6     410.5     408.8     407.8     410.2
## adjCV     401.8     403.9     405.6     404.1     403.2     405.5
## 
## TRAINING: % variance explained
##         1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
## X         38.12    53.46    66.05    74.49    79.33    84.56    87.09
## Salary    33.58    38.96    41.57    42.43    44.04    45.59    47.05
##         8 comps  9 comps  10 comps  11 comps  12 comps  13 comps  14 comps
## X         90.74    92.55     93.94     97.23     97.88     98.35     98.85
## Salary    47.53    48.42     49.68     50.04     50.54     50.78     50.92
##         15 comps  16 comps  17 comps  18 comps  19 comps
## X          99.11     99.43     99.78     99.99    100.00
## Salary     51.04     51.11     51.15     51.16     51.18</code></pre>
<pre class="r"><code>validationplot(pls.fit, val.type = &quot;MSEP&quot;)</code></pre>
<p><img src="DataMedicine_Lecture8_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<pre class="r"><code>pls.pred = predict(pls.fit, x[-train,], ncomp = 2)
mean((pls.pred-y.test)^2)</code></pre>
<pre><code>## [1] 101417.5</code></pre>
<pre class="r"><code>pls.fit=plsr(Salary~., data=Hitters, scale=TRUE, ncomp=2)
summary(pls.fit)</code></pre>
<pre><code>## Data:    X dimension: 263 19 
##  Y dimension: 263 1
## Fit method: kernelpls
## Number of components considered: 2
## TRAINING: % variance explained
##         1 comps  2 comps
## X         38.08    51.03
## Salary    43.05    46.40</code></pre>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
